Programming Problem
Measuring Performance of Network Gateway (30 marks)
You will build a discrete event simulator in Python to simulate packet arrivals and departures in a gateway and measure some performance metrics. The gateway can be modelled as a single FCFS server with a buffer that is large enough to store up to K packets that are waiting for service regardless of their sizes, that is a 64 byte packet and a 1024 byte packet take up the same amount of memory. Notice that at most one packet can be in service at any given time and upon service completion this packet will be sent out, i.e., it is forwarded to an output port of the gateway. Suppose the gateway can process L bytes of data per second, which can be the content of one or multiple packets. For example, if there are two packets in the queue with size l and L − l bytes, respectively, both of them are processed sequentially and are sent out 1 second after service starts for the first one.
You are given an ASCII packet trace file that contains multiple lines, each line describing the time that a packet arrived at the gateway in seconds since the start of the trace, and its size in bytes. The format of this file is exactly the same as the trace file that was provided for Assignment 1, so every line is twenty bytes including the newline character, and arrival time and packet size are separated by a number space characters. Your task is to write a simulator, called perf measure.py, that takes the input trace, the maximum number of packets that can be queued K, the processing speed of the gateway L, and the length of simulation in seconds T1, and simulates arrival and departure events in the order that they happen.
To build the discrete event simulator, you need to keep track of the time that each event will happen using an appropriate data structure and be able to quickly find the event that has the earliest occurrence time so that it is
1Note that simulation may end before your simulator reaches the end of the input trace and that the size of the system is K + 1 packets if the buffer can hold a maximum of K packets.
 2
possible to jump to the time that this event will occur. Thus, the actual running time of your simulator will depend on the number of events that occur by time T rather than T itself. Once the simulation ends, your program must print the following statistics to the standard output:
• the number of packets that were sent out by the gateway by T ;
• the total number of packets that were blocked by T ;
• the total amount of time (in seconds, reported to 6 decimal places) that the server was idle; • the mean number of packets seen in the system by an arrival.
Your program will be tested as follows:
The output of your program must be formatted as shown above. You can assume that all input arguments are valid.
You need to explain in a document, separate from your code, what data structure you used to store events, how events were added or removed from this data structure, what is the running complexity of your code, and how desired performance metrics are calculated. To test your program you can use the packet trace file uploaded to eClass for Assignment 1 or create a new trace using the traffic generator you developed for that assignment.